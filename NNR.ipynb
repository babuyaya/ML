{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_excel('3.xlsx')\n",
    "x = data.iloc[:, :2].values  # 修改特征列数量\n",
    "y = data.iloc[:, -1].values  # 目标列\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "activation_map = {0: 'relu', 1: 'sigmoid', 2: 'tanh'}\n",
    "\n",
    "def create_model(hidden_layers, neurons, learning_rate, activation_code, dropout_rate=0.5, l2_reg=0.01):\n",
    "    activation = activation_map[int(activation_code)]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons), input_dim=x.shape[1], activation=activation, kernel_regularizer=l2(l2_reg)))\n",
    "    for _ in range(int(hidden_layers)):\n",
    "        model.add(Dense(int(neurons), activation=activation, kernel_regularizer=l2(l2_reg)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def optimize(hidden_layers, neurons, learning_rate, activation_code):\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    r2_scores = []\n",
    "    for train_idx, val_idx in kfold.split(x):\n",
    "        train_x, val_x = x[train_idx], x[val_idx]\n",
    "        train_y, val_y = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = create_model(hidden_layers, neurons, learning_rate, activation_code)\n",
    "        model.fit(train_x, train_y, epochs=200, batch_size=32, verbose=0)\n",
    "        predictions = model.predict(val_x).flatten()\n",
    "        r2 = r2_score(val_y, predictions)\n",
    "        r2_scores.append(r2)\n",
    "    return np.mean(r2_scores)\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "\n",
    "def track_optimize(hidden_layers, neurons, learning_rate, activation_code):\n",
    "    global best_r2, best_params\n",
    "    r2 = optimize(hidden_layers, neurons, learning_rate, activation_code)\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_params = {\n",
    "            'hidden_layers': hidden_layers,\n",
    "            'neurons': neurons,\n",
    "            'learning_rate': learning_rate,\n",
    "            'activation': activation_map[int(activation_code)]\n",
    "        }\n",
    "    return r2\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=track_optimize, \n",
    "    cv=10,\n",
    "    pbounds={\n",
    "        'hidden_layers': (1, 5),\n",
    "        'neurons': (10, 200),\n",
    "        'learning_rate': (0.0001, 0.1),\n",
    "        'activation_code': (0, 2)\n",
    "    },\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "optimizer.set_gp_params(alpha=1e-4)\n",
    "optimizer.maximize(n_iter=100000, init_points=10)\n",
    "\n",
    "if best_params is None:\n",
    "    raise ValueError(\"最佳参数未正确更新。请检查优化目标函数。\")\n",
    "\n",
    "best_model = create_model(\n",
    "    hidden_layers=best_params['hidden_layers'],\n",
    "    neurons=best_params['neurons'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    activation_code=int(list(activation_map.keys())[list(activation_map.values()).index(best_params['activation'])])\n",
    ")\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "best_model.fit(train_x, train_y, epochs=200, batch_size=32, verbose=0) \n",
    "train_pred = best_model.predict(train_x).flatten()\n",
    "test_pred = best_model.predict(test_x).flatten()\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_mae = mean_absolute_error(train_y, train_pred)\n",
    "train_r2 = r2_score(train_y, train_pred)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(test_y, test_pred)\n",
    "test_r2 = r2_score(test_y, test_pred)\n",
    "\n",
    "print(f'Train - MSE: {train_mse}, RMSE: {train_rmse}, MAE: {train_mae}, R^2 score: {train_r2}')\n",
    "print(f'Test - MSE: {test_mse}, RMSE: {test_rmse}, MAE: {test_mae}, R^2 score: {test_r2}')\n",
    "print(f'Best parameters found: {best_params}')\n",
    "print(f'Best R^2 score during optimization: {best_r2}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
